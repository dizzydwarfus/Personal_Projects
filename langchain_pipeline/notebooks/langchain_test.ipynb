{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "secrets = dotenv_values(r\"..\\..\\langchain_pipeline\\.env\")\n",
    "os.environ['OPENAI_API_KEY'] = secrets['openai_api']\n",
    "os.environ['SERPAPI_API_KEY'] = secrets['serp_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "openai_models_url = \"https://api.openai.com/v1/models\"\n",
    "\n",
    "with get_openai_callback() as openai:\n",
    "    openai_models = requests.get(openai_models_url, headers={\"Authorization\": \"Bearer \" + secrets['openai_api']}).json()\n",
    "    print(openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_models(all_models: dict, re_pattern: str = 'gpt'):\n",
    "    gpt_models = [i['id'] for i in all_models['data'] if re.search(re_pattern, i['id'])]\n",
    "    return gpt_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-3.5-turbo-16k-0613',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-3.5-turbo-16k',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'gpt-3.5-turbo-0301']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_models(openai_models, re_pattern='gpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ik ga vanavond naar de bioscoop om een film te kijken.\n",
      "\n",
      "Translation: I am going to the cinema tonight to watch a movie.\n",
      "Total Tokens: 95\n",
      "Prompt Tokens: 66\n",
      "Completion Tokens: 29\n",
      "Total Cost (USD): $0.00015700000000000002\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a professional English and Dutch translator. You will be provided a prompt in either dutch or english, and you will have to answer the prompt and then provide a translation to Dutch or English.\"),\n",
    "    HumanMessage(content=\"Tell me a sentence in dutch that an intermediate level person can understand.\")\n",
    "]\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    response = chat_llm(messages)\n",
    "    print(response.content)\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what a beagle is and if it can have hair.\n",
      "Action: Search\n",
      "Action Input: \"Beagle\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe beagle is a breed of small scent hound, similar in appearance to the much larger foxhound. The beagle was developed primarily for hunting hare, known as beagling.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out if a beagle can have hair.\n",
      "Action: Search\n",
      "Action Input: \"Beagle hair\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDo Beagles have Hair or Fur? A well-debated question! Beagles have fur, although technically, hair and fur are the same thing (keratin), and on ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Beagles have fur, not hair.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Total Tokens: 858\n",
      "Prompt Tokens: 784\n",
      "Completion Tokens: 74\n",
      "Total Cost (USD): $0.01716\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = agent.run(\n",
    "        \"What is a beagle that does not have hair?\"\n",
    "    )\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatModel Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "MEMORY_KEY = 'chat_history'\n",
    "memory = ConversationBufferMemory(memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\"])\n",
    "agent = initialize_agent(tools, chat_model, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = agent.run(\n",
    "        \"What is a beagle that does not have hair?\"\n",
    "    )\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Nice to meet you, Lian! How can I assist you today?\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Nice to meet you, Lian! How can I assist you today?\n",
      "Tokens Used: 521\n",
      "\tPrompt Tokens: 490\n",
      "\tCompletion Tokens: 31\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.000797\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    print(agent.run(\n",
    "        \"Hi, my name is Lian, and I am testing your memory.\"\n",
    "    ))\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Sure, I'd be happy to come up with a nickname for you! Could you please provide me with some information about yourself? For example, what are some of your interests or characteristics that you would like the nickname to reflect?\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Sure, I'd be happy to come up with a nickname for you! Could you please provide me with some information about yourself? For example, what are some of your interests or characteristics that you would like the nickname to reflect?\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Sure, I'd be happy to come up with a nickname for you! Could you please provide me with some information about yourself? For example, what are some of your interests or characteristics that you would like the nickname to reflect?\n"
     ]
    }
   ],
   "source": [
    "print(agent.run(input=\"I want you to come up with a nickname for me.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
